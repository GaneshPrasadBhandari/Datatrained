{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["arnings.filterwarnings(\"ignore\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from datetime import datetime\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "from matplotlib import pyplot\n", "from pandas import read_csv\n", "from pandas import set_option\n", "import pandas as pd\n", "from sklearn.preprocessing import LabelEncoder\n", "from keras.utils import np_utils\n", "from sklearn import preprocessing\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.preprocessing import MultiLabelBinarizer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.impute import SimpleImputer\n", "from pandas.plotting import scatter_matrix\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import KFold\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.metrics import classification_report\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import AdaBoostClassifier\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.ensemble import ExtraTreesClassifier\n", "import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["import the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tx_data = pd.read_csv('D:/datatrained_project/practice projects/redwine/winequality-red.csv',sep=';')    \n", " \n", "# Data Statistic\n", "print(tx_data.shape)\n", "print(tx_data.head(10))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ata Wrangling clean up"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tx_data.isnull().sum()\n", "tx_data.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split the data set into train and test"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(tx_data['quality'].isnull().values.sum())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["array=tx_data.values\n", "X = array[:,0:11]\n", "Y = array[:,11]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"X\", X)\n", "print(\"Y\", Y)\n", "tx_data.groupby('quality').size()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["validation_size = 0.25\n", "seed = 50\n", "num_folds = 5\n", "scoring = 'accuracy'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size = validation_size, random_state = seed)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["pot-Check Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = []\n", "models.append(('LDA', LinearDiscriminantAnalysis()))\n", "models.append(('KNN', KNeighborsClassifier()))\n", "models.append(('CART', DecisionTreeClassifier()))\n", "models.append(('NB', GaussianNB()))\n", "models.append(('SVM', SVC()))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "names = []\n", "for name, model in models:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)\n", "    \n", "    \n", "# Compare Algorithms\n", "fig = pyplot.figure()\n", "fig.suptitle('Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluate Algorithms: Using Standardize Data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Standardize the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipelines = []\n", "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA',\n", "LinearDiscriminantAnalysis())])))\n", "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',\n", "KNeighborsClassifier())])))\n", "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',\n", "DecisionTreeClassifier())])))\n", "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB',\n", "GaussianNB())])))\n", "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC())])))\n", "results = []\n", "names = []\n", "for name, model in pipelines:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)\n", "    \n", "    \n", "# plot the distribution of the accuracy scores using box and whisker plots.\n", "# Compare Algorithms\n", "fig = pyplot.figure()\n", "fig.suptitle('Scaled Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Algorithm Tuning"]}, {"cell_type": "markdown", "metadata": {}, "source": ["SVM got the best Accuracy going with Hyper parameter tuning for SVM"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tune scaled SVM"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n", "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n", "param_grid = dict(C=c_values, kernel=kernel_values)\n", "model = SVC()\n", "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n", "grid_result = grid.fit(rescaledX, Y_train)\n", "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n", "means = grid_result.cv_results_['mean_test_score']\n", "stds = grid_result.cv_results_['std_test_score']\n", "params = grid_result.cv_results_['params']\n", "for mean, stdev, param in zip(means, stds, params):\n", "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ensemble Methods for improve the performance of algorithms<br>\n", "we will evaluate four <br>\n", "ifferent ensemble machine learning<br>\n", "algorithms, two boosting and two bagging methods:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Boosting Methods: AdaBoost (AB) and Gradient Boosting (GBM).<br>\n", "Bagging Methods: Random Forests (RF) and Extra Trees (ET)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    \n", "#ensembles\n", "ensembles = []\n", "ensembles.append(('AB', AdaBoostClassifier()))\n", "ensembles.append(('GBM', GradientBoostingClassifier()))\n", "ensembles.append(('RF', RandomForestClassifier()))\n", "ensembles.append(('ET', ExtraTreesClassifier()))\n", "results = []\n", "names = []\n", "for name, model in ensembles:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compare Algorithms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = pyplot.figure()\n", "fig.suptitle('Ensemble Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["SVM showed the most promise as a low complexity and stable model for this problem."]}, {"cell_type": "markdown", "metadata": {}, "source": ["repare the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "model = SVC(C=1.5)\n", "model.fit(rescaledX, Y_train)\n", "# estimate accuracy on validation dataset\n", "rescaledtestX = scaler.transform(X_test)\n", "predictions = model.predict(rescaledtestX)\n", "print(accuracy_score(Y_test, predictions))\n", "print(confusion_matrix(Y_test, predictions))\n", "print(classification_report(Y_test, predictions))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}