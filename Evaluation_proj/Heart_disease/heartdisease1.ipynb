{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Created on Sat Feb 27 10:36:11 2021"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@author: Ganesh\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import numpy as np\n", "import pandas as pd\n", "from matplotlib import pyplot\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.model_selection import KFold\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.linear_model import Lasso\n", "from sklearn.linear_model import ElasticNet\n", "from sklearn.neighbors import KNeighborsRegressor\n", "from sklearn.tree import DecisionTreeRegressor\n", "from sklearn.svm import SVR\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import classification_report, confusion_matrix\n", "import warnings\n", "warnings.filterwarnings('ignore')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine missing values types to replace with nan and then we will put mean(),median() or other values in those cells"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_values = [\"n/a\", \"na\", \"--\", \"?\"]\n", "#df = pd.read_csv(\"property data.csv\", na_values = missing_values)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Import the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"D:/datatrained_project/main_projects/heartdisease/heartdisease_data.csv\", header = None, na_values = missing_values)\n", "df.head(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Replace missing values using median "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["median = df.median()\n", "df.fillna(median, inplace=True)\n", "#mean = df.mean()\n", "#df.fillna(mean, inplace=True)\n", "df.head(10)\n", "df.isnull()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["integer encode"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["label_encoder = LabelEncoder()\n", "integer_encoded = label_encoder.fit_transform(df[13])\n", "print(integer_encoded)\n", "# binary encode\n", "#onehot_encoder = OneHotEncoder(sparse=False)\n", "#integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n", "#onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n", "#print(onehot_encoded)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Have a look into data<br>\n", "column and data type"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\n Column and Data Type\", df.info())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["shape of data type"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\n Shape of Dataset\", df.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["stats of dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\n Describe the Data \", df.describe())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["validate class is having only two attribute"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.isnull().values.any()\n", "df.isnull().sum().sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nan_in_df = df.isnull().values.sum()\n", "array=df.values\n", "X = array[:,0:13]\n", "Y = array[:,-1]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"X\", X)\n", "print(\"Y\", Y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["convert into binary classification problem - heart disease or no heart disease"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Y_binary = Y.copy()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Y_binary[Y_binary > 0] = 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(Y_binary[:20])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["split the dataset into train and test set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["validation_size = 0.20\n", "seed = 10\n", "num_folds =10\n", "scoring = \"accuracy\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y_binary, test_size=validation_size, random_state=seed)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["pot-Check Algorithms For Classification"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = []\n", "models.append(('LDA', LinearDiscriminantAnalysis()))\n", "models.append(('KNN', KNeighborsClassifier()))\n", "models.append(('CART', DecisionTreeClassifier()))\n", "models.append(('NB', GaussianNB()))\n", "models.append(('SVM', SVC()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["pot-Check Algorithms For Regression<br>\n", "odels = []<br>\n", "odels.append(('LR', LinearRegression()))<br>\n", "odels.append(('LA', Lasso()))<br>\n", "odels.append(('EN', ElasticNet()))<br>\n", "odels.append(('KN', KNeighborsRegressor()))<br>\n", "odels.append(('CART', DecisionTreeRegressor()))<br>\n", "odels.append(('SVR', SVR()))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "names = []\n", "for name, model in models:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)\n", "    \n", "# Compare Algorithms\n", "fig = pyplot.figure()\n", "fig.suptitle('Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluate Algorithms: Standardize/Normalize data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["to avoid data leakage when we transform the data. A good way to avoid leakage is to use pipelines<br>\n", "that standardize the data and build the # model for each fold in the cross-validation test harness.<br>\n", "That way we can get a fair estimation of how each model with standardized data might perform on unseen data."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Standardize the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipelines = []\n", "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression())])))\n", "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA', LinearDiscriminantAnalysis())])))\n", "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])))\n", "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeClassifier())])))\n", "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB', GaussianNB())])))\n", "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC())])))\n", "results = []\n", "names = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for name, model in pipelines:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)\n", "    \n", "    \n", "# Compare Algorithms\n", "fig = pyplot.figure()\n", "fig.suptitle('Scaled Algorithm Comparison')\n", "ax = fig.add_subplot(111)\n", "pyplot.boxplot(results)\n", "ax.set_xticklabels(names)\n", "pyplot.show()    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tuning KNN"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tune scaled KNN"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n", "param_grid = dict(n_neighbors=neighbors)\n", "model = KNeighborsClassifier()\n", "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n", "grid_result = grid.fit(rescaledX, Y_train)\n", "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n", "means = grid_result.cv_results_['mean_test_score']\n", "stds = grid_result.cv_results_['std_test_score']\n", "params = grid_result.cv_results_['params']\n", "for mean, stdev, param in zip(means, stds, params):\n", "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tuning SVM<br>\n", "tune two key parameters of the SVM algorithm, the value of C (how much to relax the<br>\n", "margin) and the type of kernel. The default for SVM (the SVC class) is to use the Radial<br>\n", "Basis Function (RBF) kernel with a C value set to 1.0. Like with KNN, we will perform a grid<br>\n", "search using 10-fold cross-validation with a standardized copy of the training dataset. We will<br>\n", "try a number of simpler kernel types and C values with less bias and more bias (less than and<br>\n", "more than 1.0 respectively)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["une scaled SVM"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n", "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n", "param_grid = dict(C=c_values, kernel=kernel_values)\n", "model = SVC()\n", "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n", "grid_result = grid.fit(rescaledX, Y_train)\n", "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n", "means = grid_result.cv_results_['mean_test_score']\n", "stds = grid_result.cv_results_['std_test_score']\n", "params = grid_result.cv_results_['params']\n", "for mean, stdev, param in zip(means, stds, params):\n", "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n", "    \n", "    \n", "# #########Ensemble Methods###########"]}, {"cell_type": "markdown", "metadata": {}, "source": ["evaluate four different ensemble machine learning<br>\n", "algorithms, two boosting and two bagging methods:<br>\n", "1. Boosting Methods: AdaBoost (AB) and Gradient Boosting (GBM).<br>\n", "2. Bagging Methods: Random Forests (RF) and Extra Trees (ET)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["ensembles"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ensembles = []\n", "ensembles.append(('AB', AdaBoostClassifier()))\n", "ensembles.append(('GBM', GradientBoostingClassifier()))\n", "ensembles.append(('RF', RandomForestClassifier()))\n", "ensembles.append(('ET', ExtraTreesClassifier()))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "names = []\n", "for name, model in ensembles:\n", "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n", "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n", "    results.append(cv_results)\n", "    names.append(name)\n", "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "    print(msg)    \n", "    \n", "    \n", "# Finalize model\n", "# SVM showed the most promise as a low complexity and stable model for this problem. In\n", "# so Finalize the model by training it on the entire training dataset and make\n", "# predictions for the hold-out validation dataset to confirm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["prepare the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = StandardScaler().fit(X_train)\n", "rescaledX = scaler.transform(X_train)\n", "model = SVC(C=1.5)\n", "model.fit(rescaledX, Y_train)\n", "# estimate accuracy on validation dataset\n", "rescaledValidationX = scaler.transform(X_validation)\n", "predictions = model.predict(rescaledValidationX)\n", "print(accuracy_score(Y_validation, predictions))\n", "print(confusion_matrix(Y_validation, predictions))\n", "print(classification_report(Y_validation, predictions))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}